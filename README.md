# taskmodel_encoder_v3
What's new

- Stop and go demonstration + simple speech input (e.g., carry the cup like this) without detailed step-by-step instructions

How it works
-video splitting based on luminance
-grasp/release detection by cheking the hand appearances
-task recognition based on textual-based actoin recognition. Texts are obtained using vision-based action recognition and target object name